setInverse <- function(inverse) invr <<- inverse
getInverse <- function() invr
list(set = set,
get = get,
setInverse = setInverse,
getInverse = getInverse)
}
cacheSolve <- function(x, ...) {
invr <- x$getInverse()
if (!is.null(invr)) {
message("getting cached data")
return(invr)
}
mat <- x$get()
invr <- solve(mat, ...)
x$setInverse(invr)
invr
}
my_matrix <- makeCacheMatrix(matrix(1:4, 2, 2))
my_matrix$get()
my_matrix$getInverse()
cacheSolve(my_matrix)
cacheSolve(my_matrix)
cacheSolve(my_matrix)
my_matrix$getInverse()
my_matrix$set(matrix(c(2, 2, 1, 4), 2, 2))
my_matrix$get()
my_matrix$getInverse()
cacheSolve(my_matrix)
cacheSolve(my_matrix)
makeCacheMatrix <- function(x = matrix()) {
# initial inv
inv <- NULL
# set the input matrix
set <- function(y) {
x <<- y
inv <<- NULL
}
# get the input matrix
get <- function() x
# set the inverse matrix of the input matrix
setInverse <- function(inverse) inv <<- inverse
# get the inverse matrix of the input matrix
getInverse <- function() inv
#make a list
list(set = set, get = get,
setInverse = setInverse,
getInverse = getInverse)
}
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
inv <- x$getInverse()
# determine whether we have calculated the inverse matrix before
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
# compute the inverse matrix
inv <- solve(data, ...)
# store the inverse matrix into the cache
x$setInverse(inv)
inv
}
my_matrix <- makeCacheMatrix(matrix(1:4, 2, 2))
my_matrix$get()
my_matrix$getInverse()
cacheSolve(my_matrix)
cacheSolve(my_matrix)
library(swirl)
ls()
rm(list=ls())
swirl()
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants,10L)
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period)
STR(plants)
str(plants)
swirl()
swirl()
swirl()
?sample
sample(1:6,4,replace = TRUE)
sample(1:6,4,replace = TRUE)
sample(1:20,10)
sample(letters,26)
skip
skip()
letters
sample(letters)
skip()
flips <- prob = c(0.3, 0.7)
skip()
flips
sum(flips)
?rbinom
skip()
flips2 <- rbinom(1, size = 100, prob = 0.7)
skip()
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10, mean = 100, sd = 25)
?rpois
rnorm(rpois(5), mean = 10)
rpois(5), 10)
rpois(5, 10)
replicate(100,rpois(5,10))
my_pois  <- replicate(100, rpois(5, 10))
mmy_pois
my_pois
cm <- colMeans(my_pois)
hist(cm)
data("cars")
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x = cars$speed, y = cars$dist)
plot(y = cars$speed, x = cars$dist)
?plot
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(cars, main = "My Plot")
plot(cars, sub = "My Plot Subtitle")
plot(cars,col(2) = "red")
plot(cars,col(2)="red")
skip()
plot(cars,col=2)
plot(cars, xlim = c(10, 15))
plot(cars,pch=2)
load(mtcars)
skip()
?boxplot
boxplot(mtcars,formula = mpg ~ cyl)
boxplot(formula = mpg ~ cyl,data = mtcars)
hist(mtcars$mpg)
set.seed(1)
rpois(5,2)
rpois(5,2)
rpois(5,2)
library("swirl")
swirl()
quit
exit
?
break
break
exit
help()
skip
end
library("swirl")
swirl()
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility ~ ., swiss)
vif(mdl)
mdl2 <- lm(Fertility ~ . -Examination, swiss)
vif(mdl2)
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3))/2
omnitest(correctExpr='n/d')
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
ravenData
mdl <- glm(ravenWinNum ~ ravenScore, binomial, ravenData)
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
var(rpois(1000, 50))
nxt()
View(hits)
class(hits[,'date'])
class(hits[,'date'])
as.integer(head(hits[,'date'])
)
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
mdl2 <- glm(simplystats ~ date, poisson, hits, offset=log(visits+1))
qpois(.95, mdl2$fitted.values[704])
install.packages("rmarkdown")
install.packages("caret")
library(caret)
library(caret); library(kernlab); data(spam)
install.packages("kernlab")
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=FALSE)
training <- spam[inTrain]
testing <- spam[-inTrain,]
dim(training)
inTrain
training
dim(training)
head(training)
set.seed(32323)
folds <- createFolds(y=spam$type,k=10,list=TRUE,returnTrain = TRUE)
sapply(folds,length)
folds[[1]][1:10]
inTrain <- createDataPartition(y=spam$type,p=0.75, list = FALSE)
training <- spam[inTrain]
testing <- spam[-inTrain,]
modelFit <- train(type ~.,data=training,method="glm")
modelFit <- train(type~.,data = training, method="glm")
modelFit <- train(type ~,data = training, method="glm")
modelFit <- train(type~.,data = training, method="glm")
args(train.default)
modelFit <- train(type~.,data = training, method="glm")
modelFit <- train(type ~. ,data = training, method="glm")
modelFit <- train(type,data = training, method="glm")
modelFit <- train(type~,data = training, method="glm")
modelFit <- train(type~.,data = training, method="glm")
modelFit <- train(type~.,data=training, method="glm")
install.packages("ISLR")
library(ISRL)
library(ISLR)
library(ggplot2)
data("Wage")
summary(wage)
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,p=0.7, list = FALSE)
training <- wage[inTrain,]
training <- Wage[inTrain,]
testing <- Wage[-InTrain,]
testing <- Wage[-inTrain,]
dim(training) ; dim(testing)
featurePlot(x=trainig[,c("age","education","jobclass")],y=training$wage,plot="pairs")
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qq <- qplot(age,wage,colour=education,data=training)
qq + geom_smooth(method = 'lm', formula=y~x)
cutWage <- cur2(training$wage,g=3)
cutWage <- cut2(training$wage,g=3)
install.packages("Hmisc")
cutWage <- cut2(training$wage,g=3)
library(Hmisc)
cutWage <- cut2(training$wage,g=3)
table(cutWage)
p1 <- qplot(cutWage,age,data=training,fill=cutWage,geom=c("boxplot"))
p1
library(splines)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
# fit rf predictor relating the factor variable y
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
# RF Accuracy: 0.6060606
confusionMatrix(predRf, vowel.test$y)$overall[1]
# GBM Accuracy: 0.530303
confusionMatrix(predGBM, vowel.test$y)$overall[1]
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
head(pred)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy # Agreement Accuracy: 0.6569579
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
library(ElemStatLearn)
install.packages("caret")
install.packages("ElemStatLearn")
install.packages("AppliedPredictiveModeling")
install.packages("pgmm")
install.packages("rpart")
install.packages("gbm")
install.packages("lubridate")
install.packages("forecast")
install.packages("e1071")
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
confusionMatrix(predRf, vowel.test$y)$overall[1]
confusionMatrix(predGBM, vowel.test$y)$overall[1]
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
head(pred)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData <- data.frame(diagnosis, predictors)
inTrain <- createDataPartition(adData$diagnosis, p=3/4)[[1]]
training <- adData[inTrain, ]
testing <- adData[-inTrain, ]
dim(adData)
set.seed(62433)
fitRf <- train(diagnosis ~ ., data=training, method="rf")
fitGBM <- train(diagnosis ~ ., data=training, method="gbm")
fitLDA <- train(diagnosis ~ ., data=training, method="lda")
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
fit <- train(diagnosis ~., data=pred, method="rf")
predFit <- predict(fit, testing)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGBM, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength,
p=3/4)[[1]]
training <- concrete[inTrain, ]
testing <- concrete[-inTrain, ]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength,
p=3/4)[[1]]
training <- concrete[inTrain, ]
testing <- concrete[-inTrain, ]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
fit
plot.enet(fit$finalModel, xvar="penalty", use.color=T)
library(lubridate)  # For year() function below
library(forecast)
dat <- read.csv("./data/gaData.csv")
training <- dat[year(dat$date) < 2012, ]
testing <- dat[(year(dat$date)) > 2011, ]
tstrain <- ts(training$visitsTumblr)
fit <- bats(tstrain)
fit
pred <- forecast(fit, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
# How many of the testing points is the true value within the
# 95% prediction interval bounds?
prop.table(table(predComb$in95))[2] # 0.9617021
install.packages("rattle")
install.packages("rattle")
install.packages("rattle")
install.packages("RGtk2")
install.packages("RGtk2Extras")
library(rattle)
library(rattle)
library(Hmisc)
library(caret)
library(randomForest)
library(foreach)
library(doParallel)
set.seed(998)
training.file   <- 'pml-training.csv'
test.cases.file <- 'pml-test.csv'
training.url    <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
test.cases.url  <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
download.file(training.url, training.file)
download.file(test.cases.url,test.cases.file )
training.df   <-read.csv(training.file, na.strings=c("NA","#DIV/0!", ""))
test.cases.df <-read.csv(test.cases.file , na.strings=c("NA", "#DIV/0!", ""))
training.df<-training.df[,colSums(is.na(training.df)) == 0]
test.cases.df <-test.cases.df[,colSums(is.na(test.cases.df)) == 0]
training.df   <-training.df[,-c(1:7)]
test.cases.df <-test.cases.df[,-c(1:7)]
inTraining.matrix    <- createDataPartition(training.df$classe, p = 0.75, list = FALSE)
training.data.df <- training.df[inTraining.matrix, ]
testing.data.df  <- training.df[-inTraining.matrix, ]
registerDoParallel()
classe <- training.data.df$classe
variables <- training.data.df[-ncol(training.data.df)]
install.packages("doParallel")
library(Hmisc)
library(caret)
library(randomForest)
library(foreach)
library(doParallel)
set.seed(998)
training.file   <- 'pml-training.csv'
test.cases.file <- 'pml-test.csv'
training.url    <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
test.cases.url  <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
download.file(training.url, training.file)
download.file(test.cases.url,test.cases.file )
training.df   <-read.csv(training.file, na.strings=c("NA","#DIV/0!", ""))
test.cases.df <-read.csv(test.cases.file , na.strings=c("NA", "#DIV/0!", ""))
training.df<-training.df[,colSums(is.na(training.df)) == 0]
test.cases.df <-test.cases.df[,colSums(is.na(test.cases.df)) == 0]
training.df   <-training.df[,-c(1:7)]
test.cases.df <-test.cases.df[,-c(1:7)]
inTraining.matrix    <- createDataPartition(training.df$classe, p = 0.75, list = FALSE)
training.data.df <- training.df[inTraining.matrix, ]
testing.data.df  <- training.df[-inTraining.matrix, ]
registerDoParallel()
classe <- training.data.df$classe
variables <- training.data.df[-ncol(training.data.df)]
rf <- foreach(ntree=rep(250, 4), .combine=randomForest::combine, .packages='randomForest') %dopar% {
randomForest(variables, classe, ntree=ntree)
}
install.packages("shiny")
install.packages("rsconnect")
rsconnect::setAccountInfo(name='hjl321', token='7370E6D9DF9E08628EF220FD357F692D', secret='QcAWpb+beKsseIbf7w+BGP63FMG4xy+lQlf2USTq')
install.packages("devtools")
devtools::install_github('rstudio/shinyapps')
install.packages("digest")
devtools::install_github('rstudio/shinyapps')
install.packages("manipulate")
library(manipulate)
manipulate(plot(1:x),x = slider(1,100))
manipulate(plot(1:x),x = slider(1,100))
install.packages("googleVis")
demo(googleVis)
install_github("ropensci/plotly")
install.packages("ropensci/plotly")
devtools::install_github('ropensci/plotly')
install.packages("DBI")
devtools::install_github('ropensci/plotly')
install.packages("lazy")
devtools::install_github('ropensci/plotly')
devtools::install_github('ropensci/plotly')
install.packages("assertthat")
devtools::install_github('ropensci/plotly')
shiny::runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
runApp('C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch/ShinyApp')
setwd("C:/Data/RCource/Shiny-Application-and-Reproducible-Pitch")
shiny::runApp()
